{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from collections import defaultdict, Counter\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Muhammad Bilal\n",
      "[nltk_data]     Ahmad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Download the necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "\n",
    "def tokenize_text(text):\n",
    "    return nltk.word_tokenize(text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ngrams(tokens, n):\n",
    "    return list(ngrams(tokens, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ngram_probabilities(ngrams):\n",
    "    ngram_freqs = defaultdict(Counter)\n",
    "    for ngram in ngrams:\n",
    "        prefix = ngram[:-1]\n",
    "        next_word = ngram[-1]\n",
    "        ngram_freqs[prefix][next_word] += 1\n",
    "    \n",
    "    ngram_probabilities = defaultdict(dict)\n",
    "    for prefix, counter in ngram_freqs.items():\n",
    "        total_count = float(sum(counter.values()))\n",
    "        for word, count in counter.items():\n",
    "            ngram_probabilities[prefix][word] = count / total_count\n",
    "    \n",
    "    return ngram_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_word(test_input, ngram_probabilities, n):\n",
    "    tokens = tokenize_text(test_input)\n",
    "    if len(tokens) < n - 1:\n",
    "        raise ValueError(f\"Test input should have at least {n-1} words.\")\n",
    "    \n",
    "    prefix = tuple(tokens[-(n-1):])\n",
    "    if prefix in ngram_probabilities:\n",
    "        next_word_candidates = ngram_probabilities[prefix]\n",
    "        next_word = max(next_word_candidates, key=next_word_candidates.get)\n",
    "        return next_word\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next word prediction for 'This is': a\n"
     ]
    }
   ],
   "source": [
    "# Sample input text\n",
    "sample_text = \"This is a sample text. This text is just a sample.\"\n",
    "\n",
    "# Tokenize the input text\n",
    "tokens = tokenize_text(sample_text)\n",
    "\n",
    "# Define the value of n\n",
    "n = 3\n",
    "\n",
    "# Generate n-grams\n",
    "ngrams_list = generate_ngrams(tokens, n)\n",
    "\n",
    "# Calculate n-gram probabilities\n",
    "ngram_probabilities = calculate_ngram_probabilities(ngrams_list)\n",
    "\n",
    "# Test input\n",
    "test_input = \"This is\"\n",
    "\n",
    "# Predict the next word\n",
    "next_word = predict_next_word(test_input, ngram_probabilities, n)\n",
    "print(f\"Next word prediction for '{test_input}': {next_word}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
