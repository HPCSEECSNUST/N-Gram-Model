{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Abdul\n",
      "[nltk_data]     Rehman\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import requests\n",
    "from collections import defaultdict, Counter\n",
    "nltk.download('punkt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer_1(text):\n",
    "    tokenized_text = nltk.word_tokenize(text)\n",
    "    return tokenized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ngrams(tokenized_text,n):\n",
    "    ngrams = list(zip(*[tokenized_text[i:] for i in range(n)]))\n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Describing the Calculate_frequency function**\n",
    "\n",
    "now for the calculate frequenct the defaultdic library of pyhton is being used and it is being made with subclass Counter that will consider the words as keys and value as there count.\n",
    "\n",
    "Later the context_count is being structured like this the example:\n",
    "\n",
    "Suppose context_counts is:\n",
    "\n",
    "{\n",
    "    \n",
    "    ('I',): Counter({'love': 10, 'like': 5}),\n",
    "    \n",
    "    ('love',): Counter({'natural': 5, 'chocolate': 15}),\n",
    "}\n",
    "\n",
    "now it will count in the ngrams how many time what words succeeds a specfic word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Calculate_frequency(ngrams):\n",
    "    context_counts = defaultdict(Counter)\n",
    "    for ngram in ngrams:\n",
    "        n_minus_1_word = ngram[:-1]\n",
    "        n_word = ngram[-1]\n",
    "        context_counts[n_minus_1_word][n_word] += 1\n",
    "    return context_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Calculate_probilities(context_count):\n",
    "    probilities = defaultdict(dict)\n",
    "    for n_minus_1_word, individual_n_count in context_count.items():\n",
    "        all_occurances = sum(individual_n_count.values())\n",
    "        for word , count in individual_n_count.items():\n",
    "            probilities[n_minus_1_word][word] = count / all_occurances\n",
    "    return probilities\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_synonyms(word):\n",
    "    response = requests.get(f\"https://api.datamuse.com/words?rel_syn={word}\")\n",
    "    if response.status_code == 200:\n",
    "        synonyms = [item['word'] for item in response.json()]\n",
    "        # print(synonyms)\n",
    "        return synonyms\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_n_word(word, probabilities):\n",
    "    word = word.split(\" \")\n",
    "    word = tuple(word)\n",
    "    # print(word)\n",
    "    if word in probabilities:\n",
    "        predicted_word =  max(probabilities[word], key=probabilities[word].get)\n",
    "        synonyms =  fetch_synonyms(predicted_word)\n",
    "        return predicted_word, synonyms\n",
    "    else:\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Natural language processing is fascinating. Language is a complex system that allows humans to communicate. Understanding language involves understanding syntax, semantics, and context. Language processing systems need to understand these aspects to effectively process language. The field of natural language processing combines computer science, artificial intelligence, and linguistics to create systems that can understand and generate human language. These language processing systems are used in applications such as speech recognition, machine translation, and sentiment analysis. As language processing technology advances, the ability of computers to understand and interact with humans through language will continue to improve.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "['Natural', 'language', 'processing', 'is', 'fascinating', '.', 'Language', 'is', 'a', 'complex', 'system', 'that', 'allows', 'humans', 'to', 'communicate', '.', 'Understanding', 'language', 'involves', 'understanding', 'syntax', ',', 'semantics', ',', 'and', 'context', '.', 'Language', 'processing', 'systems', 'need', 'to', 'understand', 'these', 'aspects', 'to', 'effectively', 'process', 'language', '.', 'The', 'field', 'of', 'natural', 'language', 'processing', 'combines', 'computer', 'science', ',', 'artificial', 'intelligence', ',', 'and', 'linguistics', 'to', 'create', 'systems', 'that', 'can', 'understand', 'and', 'generate', 'human', 'language', '.', 'These', 'language', 'processing', 'systems', 'are', 'used', 'in', 'applications', 'such', 'as', 'speech', 'recognition', ',', 'machine', 'translation', ',', 'and', 'sentiment', 'analysis', '.', 'As', 'language', 'processing', 'technology', 'advances', ',', 'the', 'ability', 'of', 'computers', 'to', 'understand', 'and', 'interact', 'with', 'humans', 'through', 'language', 'will', 'continue', 'to', 'improve', '.']\n"
     ]
    }
   ],
   "source": [
    "tokenized_text = tokenizer_1(sentence)\n",
    "print()\n",
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Natural', 'language'), ('language', 'processing'), ('processing', 'is'), ('is', 'fascinating'), ('fascinating', '.'), ('.', 'Language'), ('Language', 'is'), ('is', 'a'), ('a', 'complex'), ('complex', 'system'), ('system', 'that'), ('that', 'allows'), ('allows', 'humans'), ('humans', 'to'), ('to', 'communicate'), ('communicate', '.'), ('.', 'Understanding'), ('Understanding', 'language'), ('language', 'involves'), ('involves', 'understanding'), ('understanding', 'syntax'), ('syntax', ','), (',', 'semantics'), ('semantics', ','), (',', 'and'), ('and', 'context'), ('context', '.'), ('.', 'Language'), ('Language', 'processing'), ('processing', 'systems'), ('systems', 'need'), ('need', 'to'), ('to', 'understand'), ('understand', 'these'), ('these', 'aspects'), ('aspects', 'to'), ('to', 'effectively'), ('effectively', 'process'), ('process', 'language'), ('language', '.'), ('.', 'The'), ('The', 'field'), ('field', 'of'), ('of', 'natural'), ('natural', 'language'), ('language', 'processing'), ('processing', 'combines'), ('combines', 'computer'), ('computer', 'science'), ('science', ','), (',', 'artificial'), ('artificial', 'intelligence'), ('intelligence', ','), (',', 'and'), ('and', 'linguistics'), ('linguistics', 'to'), ('to', 'create'), ('create', 'systems'), ('systems', 'that'), ('that', 'can'), ('can', 'understand'), ('understand', 'and'), ('and', 'generate'), ('generate', 'human'), ('human', 'language'), ('language', '.'), ('.', 'These'), ('These', 'language'), ('language', 'processing'), ('processing', 'systems'), ('systems', 'are'), ('are', 'used'), ('used', 'in'), ('in', 'applications'), ('applications', 'such'), ('such', 'as'), ('as', 'speech'), ('speech', 'recognition'), ('recognition', ','), (',', 'machine'), ('machine', 'translation'), ('translation', ','), (',', 'and'), ('and', 'sentiment'), ('sentiment', 'analysis'), ('analysis', '.'), ('.', 'As'), ('As', 'language'), ('language', 'processing'), ('processing', 'technology'), ('technology', 'advances'), ('advances', ','), (',', 'the'), ('the', 'ability'), ('ability', 'of'), ('of', 'computers'), ('computers', 'to'), ('to', 'understand'), ('understand', 'and'), ('and', 'interact'), ('interact', 'with'), ('with', 'humans'), ('humans', 'through'), ('through', 'language'), ('language', 'will'), ('will', 'continue'), ('continue', 'to'), ('to', 'improve'), ('improve', '.')]\n"
     ]
    }
   ],
   "source": [
    "ngrams = make_ngrams(tokenized_text,2)\n",
    "print(ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "defaultdict(<class 'collections.Counter'>, {('Natural',): Counter({'language': 1}), ('language',): Counter({'processing': 4, '.': 2, 'involves': 1, 'will': 1}), ('processing',): Counter({'systems': 2, 'is': 1, 'combines': 1, 'technology': 1}), ('is',): Counter({'fascinating': 1, 'a': 1}), ('fascinating',): Counter({'.': 1}), ('.',): Counter({'Language': 2, 'Understanding': 1, 'The': 1, 'These': 1, 'As': 1}), ('Language',): Counter({'is': 1, 'processing': 1}), ('a',): Counter({'complex': 1}), ('complex',): Counter({'system': 1}), ('system',): Counter({'that': 1}), ('that',): Counter({'allows': 1, 'can': 1}), ('allows',): Counter({'humans': 1}), ('humans',): Counter({'to': 1, 'through': 1}), ('to',): Counter({'understand': 2, 'communicate': 1, 'effectively': 1, 'create': 1, 'improve': 1}), ('communicate',): Counter({'.': 1}), ('Understanding',): Counter({'language': 1}), ('involves',): Counter({'understanding': 1}), ('understanding',): Counter({'syntax': 1}), ('syntax',): Counter({',': 1}), (',',): Counter({'and': 3, 'semantics': 1, 'artificial': 1, 'machine': 1, 'the': 1}), ('semantics',): Counter({',': 1}), ('and',): Counter({'context': 1, 'linguistics': 1, 'generate': 1, 'sentiment': 1, 'interact': 1}), ('context',): Counter({'.': 1}), ('systems',): Counter({'need': 1, 'that': 1, 'are': 1}), ('need',): Counter({'to': 1}), ('understand',): Counter({'and': 2, 'these': 1}), ('these',): Counter({'aspects': 1}), ('aspects',): Counter({'to': 1}), ('effectively',): Counter({'process': 1}), ('process',): Counter({'language': 1}), ('The',): Counter({'field': 1}), ('field',): Counter({'of': 1}), ('of',): Counter({'natural': 1, 'computers': 1}), ('natural',): Counter({'language': 1}), ('combines',): Counter({'computer': 1}), ('computer',): Counter({'science': 1}), ('science',): Counter({',': 1}), ('artificial',): Counter({'intelligence': 1}), ('intelligence',): Counter({',': 1}), ('linguistics',): Counter({'to': 1}), ('create',): Counter({'systems': 1}), ('can',): Counter({'understand': 1}), ('generate',): Counter({'human': 1}), ('human',): Counter({'language': 1}), ('These',): Counter({'language': 1}), ('are',): Counter({'used': 1}), ('used',): Counter({'in': 1}), ('in',): Counter({'applications': 1}), ('applications',): Counter({'such': 1}), ('such',): Counter({'as': 1}), ('as',): Counter({'speech': 1}), ('speech',): Counter({'recognition': 1}), ('recognition',): Counter({',': 1}), ('machine',): Counter({'translation': 1}), ('translation',): Counter({',': 1}), ('sentiment',): Counter({'analysis': 1}), ('analysis',): Counter({'.': 1}), ('As',): Counter({'language': 1}), ('technology',): Counter({'advances': 1}), ('advances',): Counter({',': 1}), ('the',): Counter({'ability': 1}), ('ability',): Counter({'of': 1}), ('computers',): Counter({'to': 1}), ('interact',): Counter({'with': 1}), ('with',): Counter({'humans': 1}), ('through',): Counter({'language': 1}), ('will',): Counter({'continue': 1}), ('continue',): Counter({'to': 1}), ('improve',): Counter({'.': 1})})\n"
     ]
    }
   ],
   "source": [
    "frequency = Calculate_frequency(ngrams)\n",
    "print()\n",
    "print(frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "defaultdict(<class 'dict'>, {('Natural',): {'language': 1.0}, ('language',): {'processing': 0.5, 'involves': 0.125, '.': 0.25, 'will': 0.125}, ('processing',): {'is': 0.2, 'systems': 0.4, 'combines': 0.2, 'technology': 0.2}, ('is',): {'fascinating': 0.5, 'a': 0.5}, ('fascinating',): {'.': 1.0}, ('.',): {'Language': 0.3333333333333333, 'Understanding': 0.16666666666666666, 'The': 0.16666666666666666, 'These': 0.16666666666666666, 'As': 0.16666666666666666}, ('Language',): {'is': 0.5, 'processing': 0.5}, ('a',): {'complex': 1.0}, ('complex',): {'system': 1.0}, ('system',): {'that': 1.0}, ('that',): {'allows': 0.5, 'can': 0.5}, ('allows',): {'humans': 1.0}, ('humans',): {'to': 0.5, 'through': 0.5}, ('to',): {'communicate': 0.16666666666666666, 'understand': 0.3333333333333333, 'effectively': 0.16666666666666666, 'create': 0.16666666666666666, 'improve': 0.16666666666666666}, ('communicate',): {'.': 1.0}, ('Understanding',): {'language': 1.0}, ('involves',): {'understanding': 1.0}, ('understanding',): {'syntax': 1.0}, ('syntax',): {',': 1.0}, (',',): {'semantics': 0.14285714285714285, 'and': 0.42857142857142855, 'artificial': 0.14285714285714285, 'machine': 0.14285714285714285, 'the': 0.14285714285714285}, ('semantics',): {',': 1.0}, ('and',): {'context': 0.2, 'linguistics': 0.2, 'generate': 0.2, 'sentiment': 0.2, 'interact': 0.2}, ('context',): {'.': 1.0}, ('systems',): {'need': 0.3333333333333333, 'that': 0.3333333333333333, 'are': 0.3333333333333333}, ('need',): {'to': 1.0}, ('understand',): {'these': 0.3333333333333333, 'and': 0.6666666666666666}, ('these',): {'aspects': 1.0}, ('aspects',): {'to': 1.0}, ('effectively',): {'process': 1.0}, ('process',): {'language': 1.0}, ('The',): {'field': 1.0}, ('field',): {'of': 1.0}, ('of',): {'natural': 0.5, 'computers': 0.5}, ('natural',): {'language': 1.0}, ('combines',): {'computer': 1.0}, ('computer',): {'science': 1.0}, ('science',): {',': 1.0}, ('artificial',): {'intelligence': 1.0}, ('intelligence',): {',': 1.0}, ('linguistics',): {'to': 1.0}, ('create',): {'systems': 1.0}, ('can',): {'understand': 1.0}, ('generate',): {'human': 1.0}, ('human',): {'language': 1.0}, ('These',): {'language': 1.0}, ('are',): {'used': 1.0}, ('used',): {'in': 1.0}, ('in',): {'applications': 1.0}, ('applications',): {'such': 1.0}, ('such',): {'as': 1.0}, ('as',): {'speech': 1.0}, ('speech',): {'recognition': 1.0}, ('recognition',): {',': 1.0}, ('machine',): {'translation': 1.0}, ('translation',): {',': 1.0}, ('sentiment',): {'analysis': 1.0}, ('analysis',): {'.': 1.0}, ('As',): {'language': 1.0}, ('technology',): {'advances': 1.0}, ('advances',): {',': 1.0}, ('the',): {'ability': 1.0}, ('ability',): {'of': 1.0}, ('computers',): {'to': 1.0}, ('interact',): {'with': 1.0}, ('with',): {'humans': 1.0}, ('through',): {'language': 1.0}, ('will',): {'continue': 1.0}, ('continue',): {'to': 1.0}, ('improve',): {'.': 1.0}})\n"
     ]
    }
   ],
   "source": [
    "probility = Calculate_probilities(frequency)\n",
    "print()\n",
    "print(probility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the predicted word is :  fascinating\n",
      "other words that can be used instead of fascinating are :  ['interesting', 'attractive', 'riveting', 'enchanting', 'captivating', 'gripping', 'absorbing', 'enthralling', 'bewitching', 'engrossing', 'entrancing']\n"
     ]
    }
   ],
   "source": [
    "word = \"is\"\n",
    "# print(word)\n",
    "predicted_word, synonyms = predict_n_word(word,probility)\n",
    "print(\"the predicted word is : \",predicted_word)\n",
    "print(f\"other words that can be used instead of {predicted_word} are : \", synonyms)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
