{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter, defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mubas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# necessary NLTK data files\n",
    "nltk.download('punkt')\n",
    "\n",
    "def generate_ngrams(text, n):\n",
    "    # tokenize the text into words and generate n-grams\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    n_grams = list(ngrams(tokens, n))\n",
    "    return n_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ngram_probabilities(text, n, smoothing=False):\n",
    "    n_grams = generate_ngrams(text, n)\n",
    "    n_minus_1_grams = generate_ngrams(text, n-1)\n",
    "    \n",
    "    n_gram_counts = Counter(n_grams)\n",
    "    n_minus_1_gram_counts = Counter(n_minus_1_grams)\n",
    "    \n",
    "    n_gram_probabilities = defaultdict(dict)\n",
    "    \n",
    "    vocabulary_size = len(set(word_tokenize(text.lower())))\n",
    "    \n",
    "    for n_gram in n_gram_counts:\n",
    "        n_minus_1_gram = n_gram[:-1]\n",
    "        if smoothing:\n",
    "            n_gram_probabilities[n_minus_1_gram][n_gram[-1]] = (n_gram_counts[n_gram] + 1) / (n_minus_1_gram_counts[n_minus_1_gram] + vocabulary_size)\n",
    "        else:\n",
    "            n_gram_probabilities[n_minus_1_gram][n_gram[-1]] = n_gram_counts[n_gram] / n_minus_1_gram_counts[n_minus_1_gram]\n",
    "    \n",
    "    return n_gram_probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_top_n_next_words(text, n, preceding_words, top_n=3, smoothing=True):\n",
    "    n_gram_probabilities = calculate_ngram_probabilities(text, n, smoothing=smoothing)\n",
    "    preceding_tuple = tuple(preceding_words.lower().split()[-(n-1):])\n",
    "    \n",
    "    if preceding_tuple in n_gram_probabilities:\n",
    "        sorted_predictions = sorted(n_gram_probabilities[preceding_tuple].items(), key=lambda item: item[1], reverse=True)\n",
    "        return sorted_predictions[:top_n]\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_word(text, n, preceding_words):\n",
    "    n_gram_probabilities = calculate_ngram_probabilities(text, n)\n",
    "    preceding_tuple = tuple(preceding_words.lower().split()[-(n-1):])\n",
    "    \n",
    "    if preceding_tuple in n_gram_probabilities:\n",
    "        next_word = max(n_gram_probabilities[preceding_tuple], key=n_gram_probabilities[preceding_tuple].get)\n",
    "        return next_word, n_gram_probabilities[preceding_tuple][next_word]\n",
    "    else:\n",
    "        return None, 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word next to HPC is: lab, with robability: 1.0\n",
      "The word next to in the is: hpc, with probability: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    sample_text = \"I work in the HPC Lab with my team members in the HPC Lab in the peaceful environment\"\n",
    "\n",
    "    next_word, probability = predict_next_word(sample_text, 2, \"HPC\")\n",
    "    print(f\"The word next to HPC is: {next_word}, with robability: {probability}\")\n",
    "\n",
    "    next_word, probability = predict_next_word(sample_text, 3, \"in the\")\n",
    "    print(f\"The word next to in the is: {next_word}, with probability: {probability}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next word: hpc, Probability: 0.2\n",
      "Next word: peaceful, Probability: 0.13333333333333333\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Predict the top 3 possible next words after \"HPC Lab\"\n",
    "top_predictions = predict_top_n_next_words(sample_text, 2, \"in the\", top_n=3)\n",
    "\n",
    "for word, prob in top_predictions:\n",
    "    print(f\"Next word: {word}, Probability: {prob}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
